{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f48aca6-99d4-4b5c-a0bf-233e50ef8b0f",
   "metadata": {},
   "source": [
    "# Detección de velocidad angular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0030ace-8a1b-4e5d-95f4-11b7e815c765",
   "metadata": {},
   "source": [
    "Una vez tenemos los archivos de trayectorias experimentales se ejecutan los siguientes pasos para el algoritmo:\n",
    "1. Para cada video se hace un bucle que recorre todas las partículas\n",
    "2. Para cada particula se calculan los perfiles de luminosidad de las aspas en cada fotograma\n",
    "3. Para cada par de perfiles de luminosidad consecutivos se calcula su \"time-lagged correlation function\"\n",
    "4. Se detecta (y se refina) el máximo de esas correlaciones que coincide con el desplazamiento angular de la particula entre esos dos fotogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b073e036-049e-4330-98c3-fa7e17314cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pims\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0dfd2b8-73bf-4d03-843f-085e60b3cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = [832, 800] # Dimensiones del video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e9ba3-877d-4d89-b09d-0e7e8005a62f",
   "metadata": {},
   "source": [
    "Tras importar las librerias necesarias defino algunas funciones útiles que llamaré más adelante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567e4311-42d0-426d-905b-da06449a01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_from_2D_points(array_x, array_y):\n",
    "    \"\"\" Given two 1D arrays, corresponding to 'x' and 'y' coordinates of 2D points,\n",
    "        this function returns the angle of those points directions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array_x : array\n",
    "        1D array of 'x' positions, ints or floats.        \n",
    "    array_y : array\n",
    "        1D array of 'y' positions, ints or floats.   \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        A 1D numpy array with points angles expressed in degrees.\n",
    "    \"\"\"\n",
    "\n",
    "    hipotenusas = np.linalg.norm([array_x, array_y], axis=0)\n",
    "    senos = np.abs(array_y / hipotenusas)\n",
    "    rad_angles = np.arcsin(senos)\n",
    "\n",
    "    indices_cuadrante_sup_der = np.intersect1d(np.where(np.sign(array_y)>0), np.where(np.sign(array_x)>0), assume_unique=True)\n",
    "    indices_cuadrante_sup_izq = np.intersect1d(np.where(np.sign(array_y)>0), np.where(np.sign(array_x)<0), assume_unique=True)\n",
    "    indices_cuadrante_inf_der = np.intersect1d(np.where(np.sign(array_y)<0), np.where(np.sign(array_x)>0), assume_unique=True)\n",
    "    indices_cuadrante_inf_izq = np.intersect1d(np.where(np.sign(array_y)<0), np.where(np.sign(array_x)<0), assume_unique=True)\n",
    "\n",
    "    indices_eje_izquierdo = np.intersect1d(np.where(np.sign(array_y)==0), np.where(np.sign(array_x)<0), assume_unique=True)\n",
    "    indices_eje_inferior = np.intersect1d(np.where(np.sign(array_y)<0), np.where(np.sign(array_x)==0), assume_unique=True)\n",
    "\n",
    "    rad_angles[indices_cuadrante_sup_der] = rad_angles[indices_cuadrante_sup_der] + 0\n",
    "    rad_angles[indices_cuadrante_sup_izq] = np.pi - rad_angles[indices_cuadrante_sup_izq]\n",
    "    rad_angles[indices_cuadrante_inf_der] = 2*np.pi - rad_angles[indices_cuadrante_inf_der]\n",
    "    rad_angles[indices_cuadrante_inf_izq] = rad_angles[indices_cuadrante_inf_izq] + np.pi\n",
    "\n",
    "    rad_angles[indices_eje_izquierdo] = np.pi\n",
    "    rad_angles[indices_eje_inferior] = 3*np.pi/2\n",
    "\n",
    "\n",
    "    deg_angles = np.rad2deg(rad_angles)\n",
    "    return deg_angles\n",
    "\n",
    "\n",
    "\n",
    "def maskImage(img, mask):\n",
    "    \"\"\" Masks an input image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : array\n",
    "        Input image\n",
    "    mask : array\n",
    "        True/False array with same shape as input image\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    masked_img : array\n",
    "        output masked image\n",
    "\n",
    "    \"\"\"\n",
    "    masked_img = img.copy()\n",
    "    masked_img[~mask] = 0\n",
    "    \n",
    "    return masked_img\n",
    "\n",
    "\n",
    "\n",
    "def fast_ring_mask(center, XX, YY, r_min=15, r_max=22):\n",
    "    \"\"\" Creates an OpenCV circular mask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    XX, YY : numpy arrays\n",
    "        XX, YY = np.ogrid[:800, :1280] where 800 and 1280 are height and width respectively\n",
    "    center : tuple or list, optional\n",
    "        Pair of coordinates for the mask's central point. If not specified uses: [w/2, h/2]\n",
    "    r_min, rmax : float, optional\n",
    "        Values of the mask radiuses of the ring.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mask : array\n",
    "        Mask for using with the image (array of True/False values)\n",
    "    \"\"\"\n",
    "    dist_from_center = np.linalg.norm([XX - center[1], YY - center[0]])\n",
    "    mask = np.logical_and(dist_from_center <= r_max, dist_from_center >= r_min)\n",
    "    return mask\n",
    "# Función parcial a la que solo hay que pasarle ya el centro de la partícula y crea la máscara\n",
    "XX, YY = np.ogrid[:SHAPE[1], :SHAPE[0]]\n",
    "partial_ring_mask = partial(fast_ring_mask, XX=XX, YY=YY, r_min=15, r_max=23) \n",
    "\n",
    "\n",
    "\n",
    "def get_brightness_profile_single_particle(row, video_path):\n",
    "    \"\"\"\n",
    "    This function calculates the brightness profile of a particle from its position\n",
    "    and image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : list\n",
    "        Lista con los siguientes elementos:\n",
    "            0 -> Index of the row in the original trajectories dataframe \n",
    "            1 -> nº frame\n",
    "            2 -> position, x particle center\n",
    "            3 -> positión, y particle center\n",
    "    video_path : str\n",
    "        Path to the .cine video file corresponding to the current experiment\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple withe the following items:\n",
    "    indice : int\n",
    "        Index of the row in the original trajectories dataframe \n",
    "    brillo : array\n",
    "        Array with sorted (by angle) values of brighness extrected from the blades image\n",
    "\n",
    "    \"\"\"\n",
    "    # tamaño ventana filtro savgol debe ser 21 para r_min=15, r_max=20, y 29 para r_min=15, r_max=23\n",
    "    indice, frame, x_0, y_0 = row\n",
    "    video=pims.Cine(video_path)\n",
    "    frame_orig = video.get_frame(int(frame)-1) #EL -1 ES PARA CORREGIR QUE EN LOS DATAFRAME EMPIEZO EN FRAME 1 Y NO 0, QUITAR SI FALLA\n",
    "\n",
    "    mask = partial_ring_mask([x_0, y_0])\n",
    "    frame = maskImage(frame_orig, mask)\n",
    "\n",
    "    y, x = np.where(frame != 0)\n",
    "    brillo = frame[(y,x)]\n",
    "    brillo = brillo * (255/brillo.max())\n",
    "    x_rel_to_center = x - x_0\n",
    "    y_rel_to_center = y - y_0\n",
    "    angulos = angle_from_2D_points(x_rel_to_center, y_rel_to_center)\n",
    "    sort_inds = np.argsort(angulos)\n",
    "    angulos = angulos[sort_inds]\n",
    "    brillo = brillo[sort_inds]\n",
    "    brillo = savgol_filter(brillo, window_length=29, polyorder=3)\n",
    "\n",
    "    return (int(indice), brillo)\n",
    "\n",
    "\n",
    "\n",
    "def crosscorr_lag(datax, datay, lag=0, wrap=False):\n",
    "    \"\"\" Lag-N cross correlation. \n",
    "    Shifted data filled with NaNs \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lag : int, default 0\n",
    "    datax, datay : pandas.Series objects of equal length\n",
    "    Returns\n",
    "    ----------\n",
    "    crosscorr : float\n",
    "    \"\"\"\n",
    "    datax = pd.Series(datax)\n",
    "    datay = pd.Series(datay)\n",
    "    if wrap:\n",
    "        shiftedy = datay.shift(lag)\n",
    "        shiftedy.iloc[:lag] = datay.iloc[-lag:].values\n",
    "        return datax.corr(shiftedy)\n",
    "    else: \n",
    "        return datax.corr(datay.shift(lag))\n",
    "    \n",
    "    \n",
    "    \n",
    "def find_displacement_angle_from_lagged_correlation(pair_of_arrays, N_ASPAS=14, N_NEIGHBORS_FOR_SUBPIXEL=4):\n",
    "    \"\"\"\n",
    "    Given two consecutive brightness profiles corresponding to the same particle, returns\n",
    "    the angular displacement between them by means of a lagged cross correlation (similar\n",
    "    to what is used in PIV techniques)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pair_of_arrays : list\n",
    "        List with 2 consecutive arrays each containing the brightness profile of particles in consecutive frames   \n",
    "    N_ASPAS : int, optional\n",
    "        Expected number of blades in the profile. The default is 14.\n",
    "    N_NEIGHBORS_FOR_SUBPIXEL : int, optional\n",
    "        Number of points used to refine the detected maximum of the lagged cross-correlation. The default is 4.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    angulo_desplazamiento_rad : float\n",
    "        Value, in radians, of the angular displacement between the two brighness profiles\n",
    "    \"\"\"\n",
    "    \n",
    "    # a y b son los arrays de luminosidades\n",
    "    a = pair_of_arrays[0]\n",
    "    b = pair_of_arrays[1]\n",
    "\n",
    "    # Nº de puntos (indices) en el array que corresponden a un intervalo angular de media aspa   \n",
    "    puntos_por_media_aspa = int(len(a)/(2*N_ASPAS))\n",
    "    # El lag maximo para hacer la correlacion entre los dos arrays oscila entre -0.5aspas y +0.5aspas\n",
    "    valores_lag = np.arange(-puntos_por_media_aspa, puntos_por_media_aspa)\n",
    "    \n",
    "    # Calculamos las correlaciones para esos lags\n",
    "    correlaciones = []\n",
    "    for lag in valores_lag:\n",
    "        correlaciones.append(crosscorr_lag(a, b, lag=lag))\n",
    "        \n",
    "    # Ahora tenemos que calcular el máximo de esta curva y afinar para tener más precisión\n",
    "    first_guess_max_index = np.argmax(correlaciones)\n",
    "    # Calculamos el máximo de la serie y cogemos un entorno a su alrededor donde interpolaremos\n",
    "    # con más puntos un polinomio de tercer grado para afinar la deteccion del máximo\n",
    "    # Los dos primero ifs son para tratar los casos extremos\n",
    "    if first_guess_max_index<=N_NEIGHBORS_FOR_SUBPIXEL:\n",
    "        surrounding_region = correlaciones[0 : first_guess_max_index+N_NEIGHBORS_FOR_SUBPIXEL]\n",
    "        x = np.arange(valores_lag[0], valores_lag[first_guess_max_index+N_NEIGHBORS_FOR_SUBPIXEL])\n",
    "    elif first_guess_max_index>=len(valores_lag)-N_NEIGHBORS_FOR_SUBPIXEL:\n",
    "        surrounding_region = correlaciones[first_guess_max_index-N_NEIGHBORS_FOR_SUBPIXEL :]\n",
    "        x = np.arange(valores_lag[first_guess_max_index-N_NEIGHBORS_FOR_SUBPIXEL], valores_lag[-1]+1)\n",
    "    else:\n",
    "        surrounding_region = correlaciones[first_guess_max_index-N_NEIGHBORS_FOR_SUBPIXEL+1 : first_guess_max_index+N_NEIGHBORS_FOR_SUBPIXEL]\n",
    "        x = np.arange(valores_lag[first_guess_max_index-N_NEIGHBORS_FOR_SUBPIXEL+1], valores_lag[first_guess_max_index+N_NEIGHBORS_FOR_SUBPIXEL])\n",
    "    # Aproximamos a una cúbica       \n",
    "    f = interp1d(x, surrounding_region, kind = 'cubic')   \n",
    "    x_new = np.linspace(x[0], x[-1], 300) # Nuevo array de lags para la interpolacion, con 300 valores en lugar de 2*N_NEIGHBORS_FOR_SUBPIXEL\n",
    "    y_new = f(x_new)\n",
    "    second_guess_max_index = np.argmax(y_new)\n",
    "    \n",
    "    # En todo el array del perfil de brillo de las aspas hay 2*pi radianes -> cada valor representa (2*np.pi/len(a))\n",
    "    # El desplazamiento se multiplica por eso\n",
    "    angulo_desplazamiento_rad = (2*np.pi/len(a)) * x_new[second_guess_max_index]\n",
    "    return angulo_desplazamiento_rad\n",
    "\n",
    "\n",
    "def detect_spin_from_correlation_brightness_profile_video(video_file, data_file, frame_max='max', PARALLEL=True):\n",
    "    \"\"\"\n",
    "    Calculates the angular velocity of disks with blades\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video_file : str\n",
    "        Path to the .cine experimental movie\n",
    "    data_file : str\n",
    "        Path to the .pkl.xz experimental trajectories file\n",
    "    frame_max : int, optional\n",
    "        Maximum number of frames to process. The default is 'max'.\n",
    "    PARALLEL : bool, optional\n",
    "        Use multiprocessing or not. The default is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_df : pandas DataFrame\n",
    "        Dataframe with an added column 'w' representing the instantaneous angular displacement in rad/frame\n",
    "\n",
    "    \"\"\"\n",
    "    # GRADOS_POR_ASPA = 360/14.\n",
    "    df = pd.read_pickle(data_file, compression='xz')\n",
    "    df['indice'] = df.index\n",
    "\n",
    "    rows = df[['indice','frame','x','y']].values\n",
    "    N = len(rows)\n",
    "    if frame_max != 'max':\n",
    "        sub = df[df.frame <= frame_max]\n",
    "        rows = sub[['indice','frame','x','y']].values\n",
    "        N = len(rows)\n",
    "\n",
    "    # Función parcial, ahora solo acepta como entrada una lista, de la forma [indice, n_frame, x, y]\n",
    "    partial_get_brightness_profile_single_particle = partial(get_brightness_profile_single_particle, video_path=video_file)\n",
    "    # Calculamos los angulos de los picos de brillo alrededor de las partículas.\n",
    "    # Usamos múltiples procesadores\n",
    "    N_CORES = mp.cpu_count()\n",
    "    print(f'Computing angular brightness profiles using {N_CORES} cores \\n')\n",
    "    with mp.Pool(processes=N_CORES) as pool:\n",
    "        dict_indices_max_mins = dict(list(tqdm(pool.imap(partial_get_brightness_profile_single_particle, rows), total=N, desc=f\"{video_file}\", unit=\" particles\")))\n",
    "\n",
    "    df['array_brillos'] = df['indice'].map(dict_indices_max_mins)\n",
    "    \n",
    "    \n",
    "    # Ahora, para cada partícula tengo que ir haciendo la correlacion frame a frame \n",
    "    # de los perfiles de brillo para calcular la velocidad angular\n",
    "    new_df = []\n",
    "    for t in set(df.track):\n",
    "        sub = df[df.track==t]\n",
    "        \n",
    "        # Tengo que iterar sobre tuplas de brillos correspondientes a frames consecutivos:\n",
    "        brighness_profile_pairs = [sub.iloc[i:i+2]['array_brillos'].values for i in range(len(sub))]\n",
    "        \n",
    "        if PARALLEL==True:\n",
    "            N_CORES = mp.cpu_count()\n",
    "            print(f'Correlating consecutive frames using {N_CORES} cores \\n')\n",
    "            with mp.Pool(processes=N_CORES) as pool:\n",
    "                desplazamientos_angulares = list(tqdm(pool.imap(find_displacement_angle_from_lagged_correlation, brighness_profile_pairs[:-1])))\n",
    "        else:\n",
    "            desplazamientos_angulares = list(tqdm(map(find_displacement_angle_from_lagged_correlation, brighness_profile_pairs[:-1])))\n",
    "        \n",
    "        desplazamientos_angulares.append(desplazamientos_angulares[-1]) #El ultimo elemento no lo podemos clcular, repetimos el anterior\n",
    "        sub['w'] = np.array(desplazamientos_angulares)\n",
    "        new_df.append(sub)\n",
    "        \n",
    "    new_df = pd.concat(new_df)\n",
    "        \n",
    "    #return new_df[['frame','track','x','y','w']]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f84324f-d81c-44f6-bab8-479e14661fb8",
   "metadata": {},
   "source": [
    "Ahora, ya podemos ejecutar la detección de ángulos, primero definimos algunas variables y directorios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2c0719-0e6f-41d8-a9b8-99e53955cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/malopez/Desktop/pruebasFran\\\\105fa8bdab0e675f2ce62ab9bbb422ae_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\2dad36cbc58c33e0410d2b9ee1ff9cdc_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\4195dccd212da00d52f76d98cf7e413b_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\47e6c4f6901cce30755826711f4a43bf_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\643e88ebecb763c9b60732454a4eae52_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\679bb36091b5ffccddb7e94618a5e6f6_raw_trajectories.pkl.xz',\n",
       " 'C:/Users/malopez/Desktop/pruebasFran\\\\7da0eb99bd3172dde3244f91a6caee41_raw_trajectories.pkl.xz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = 'C:/Users/malopez/Desktop/pruebasFran/' # Directorio donde están los archivos .pkl y .cine\n",
    "PARALLEL = True # Usado para paralelizar o no ciertas funciones\n",
    "\n",
    "track_files = glob.glob(FOLDER + '*_trajectories.pkl.xz', recursive=True)\n",
    "track_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5060a-a2f5-4fae-97a2-80d149915814",
   "metadata": {},
   "source": [
    "Y por último iteramos sobre todos estos archivos para sacar las velocidades angulares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a55ef-f199-43c0-b0ff-7c948392aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for track_file in track_files:\n",
    "        # Leo la información para saber cual es el archivo .cine correspondiente\n",
    "        experiment_id = os.path.split(track_file)[-1].split('_')[0]\n",
    "        info_file = folder + f'{experiment_id}_experiment_info.txt'\n",
    "        with open(info_file) as f:\n",
    "            jsonstr = json.load(f)\n",
    "        video_file = folder + os.path.split(jsonstr['original_file'])[-1]\n",
    "\n",
    "        # Llamo a la funcion que correlaciona perfiles de luminosidad\n",
    "        df = detect_spin_from_correlation_brightness_profile_video(video_file, track_file, frame_max='max', PARALLEL=PARALLEL)\n",
    "        new_df = df[['frame','track','x','y','w','natural_spin']]\n",
    "        # Paso de radianes por fotograma a aspas por fotograma\n",
    "        new_df['w'] = 14 * new_df['w'] / (2*np.pi)\n",
    "        # Guardo en un nuevo archivo\n",
    "        new_df.to_pickle(folder + f'{experiment_id}_w.pkl.xz', compression='xz')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
